---
title: "Multiple Testing When Many p-Values are Uniformly Conservative"
subtitle: "Multiple Comparisons and Selective Inference Sem. A 2020"
author: "Giora Simchoni"
institute: "Stat. and OR Department, TAU"
date: "`r Sys.Date()`"
output_dir: "images"
output:
  xaringan::moon_reader:
    css: "slides.css"
    seal: false
    includes:
      in_header: "header.html"
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false

---

class: title-slide

## Multiple Testing When Many P-Values are Uniformly Conservative

#### Qingyuan Zhao, Dylan S. Small, and Weijie Su (2019)

##### Presented by: Giora Simchoni

### Multiple Comparisons and Selective Inference Sem. A 2020

#### Stat. and OR Department, TAU
#### 2020-11-05

---
```{r child = "setup.Rmd"}
```

```{r packages, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
```

class: section-slide

# At Highest Level

---

## There's a Story

.no_shadow[
<center><img src = "images/high_level_story.png" style="width: 100%"></center>
]

---

class: section-slide

# Motivation

---

### Educational Intervention

[Cooper et al. (2003)](https://www.jstor.org/stable/3516042) Meta-Analysis:

<center><img src = "images/cooper_abstract.png" style="width: 70%"></center>

---

### A Typical (Simplified) Single-Study Model

$$y_j = \beta_0 + \beta_MX_j + \epsilon_j$$

Where:

$$y_j = \text{Student j "achievement"}$$

$$X_j = \begin{cases}
      1, & \text{Student j in Modified Calendar}\ \\
      0, & \text{Otherwise}
    \end{cases}$$

$$\epsilon_j \sim N(0, \sigma^2)$$

And we're interested in:

$$H_0: \beta_M \leq 0 \space vs. \space H_1: \beta_M > 0$$

(Yes, in some studies this could literally be a t-test)

---

### A Typical (Simplified) Meta-Study Model

- Observe $n$ studies for which we only have the bottom line, such as treatment effect $\beta_{M_i}$ or its p-value $p_i$
- Each $\beta_{M_i}$ comes with its own scale or $\sigma_i$
- Is there a "global" effect?
- One approach is to take the *effect size*s $d_i = \frac{\beta_{M_i}}{\sigma_i}$
- Let $\mu_d =E(d)$
- Use a single sample t/z-test to test the global null hypothesis:

$$H_0: \mu_d \le 0 \space vs. \space H_1: \mu_d > 0$$

---

### A (Still Simplified) Meta-Study Mixed Model

$$y_i = \mu + b_{S_i} + \epsilon_i$$

Where:

$$y_i = \text{Study i treatment effect or } \beta_{M_i}$$
$$b_{S_i} \sim N(0, \sigma_S^2) = \text{Study i random effect}$$
$$\epsilon_i \sim N(0, \sigma_i^2)$$
Where $\sigma_i^2$ is known from Study $i$.

Still the global null hypothesis would be:

$$H_0: \mu \le 0 \space vs. \space H_1: \mu > 0$$

---

### Result: "quite small"

.pull-left[
<img src = "images/cooper_results_stem_leaf.png" style="width: 100%">

]
.pull-right[
<img src = "images/cooper_results.png" style="width: 90%">
]

---

### But could there be a (qualitative) interaction?

.pull-left[

#### Quantitative (Ordinal) Interaction

```{r Ordinal-Interaction, echo=FALSE, out.width="100%"}
tibble(X = factor(c(0, 0, 1, 1)),
       Group = factor(c("A", "B", "A", "B")),
       y = c(5, 6, 6, 12)) %>%
  ggplot(aes(X, y, color = Group, group = Group)) +
  geom_line(lwd = 2) +
  geom_point(size = 8) +
  theme_light() +
  theme(axis.text.x = element_text(size = 20),
        axis.text.y = element_text(size = 20),
        axis.title.x = element_text(size = 24),
        axis.title.y = element_text(size = 24),
        legend.text = element_text(size = 20),
        legend.title = element_text(size = 20))
```

]

.pull-right[

#### Qualitative (Disordinal) Interaction

```{r Disrdinal-Interaction, echo=FALSE, out.width="100%"}
tibble(X = factor(c(0, 0, 1, 1)),
       Group = factor(c("A", "B", "A", "B")),
       y = c(9, 6, 7, 12)) %>%
  ggplot(aes(X, y, color = Group, group = Group)) +
  geom_line(lwd = 2) +
  geom_point(size = 8) +
  theme_light() +
  theme(axis.text.x = element_text(size = 20),
        axis.text.y = element_text(size = 20),
        axis.title.x = element_text(size = 24),
        axis.title.y = element_text(size = 24),
        legend.text = element_text(size = 20),
        legend.title = element_text(size = 20))
```

]

---

#### Why is the ME model unsuitable for testing qualitative interaction?

- $\sigma^2_S > 0$ significantly, was found. What does that mean?
- So, go to a Fixed Effects model and make school/district a categorical variable with ~50 levels?...
- Can the ME model incorporate interaction? Can't guess apriori (and therefore put in the model) which groups (schools, districts) belong to positive/negative treatment effect

---

class: section-slide

# Meta-Analysis as a Multiple Testing Problem

---

### Meta-Analysis as MTP

- $n$ subgroups or independent studies
- $y_i \sim N(\mu_i, \sigma_i^2)$ [Study i treatment effect or $\beta_{M_i}$]
- Single study null hypothesis: $H_{0i} = \{\mu_i \le 0\}$
- Global null hypothesis: $H_0 = \cap_{i=1}^n H_{0i} = \{\mu_i \le 0, \forall i\}$

$\implies$

- Forget the t-test or ME model
- Get the p-value $p_i$ from each study for $H_{0i}$
- Treat $p_1, ..., p_n$ with your favorite MTP handler: Bonferroni, Fisher, BH, ...
- Test the global null $H_0$ accordingly
- E.g. with Bonferroni reject $H_0$ if $min(p_i) \le \alpha/n$

---

### Testing a Global Null

- Think of any global test that is associated with a series of p-values adjusting function $p: [0, 1]^n \rightarrow [0, 1]$

- Bonferroni is really: $p^B(p_1, ... , p_n) = \min(n \cdot \min_i{p_i}, 1)$

```{r}
p_global_bonferroni <- function(p_vals) {
  n <- length(p_vals)
  return(min(n * min(p_vals), 1))
}
```

- Looks good, right?

---

### The Problem of Conservative Tests

- Suppose $Y_1, ..., Y_{100}$ are $N(\mu_i, 1)$ RVs
- Global null: $H_0 = \cap_{i=1}^n H_{0i} = \{\mu_i \le 0, \forall i\}$
- Observe $y_1, ..., y_n$
- p-value would be: $p_i = P_{H_{0i}}(Y_i > y_i) = 1 - \phi(y_i)$
- Calculate $p_1, ..., p_n$
- If in reality $\{\mu_i = 0, \forall i\} \implies p_i \sim U(0, 1)$
- If in reality e.g. $\{\mu_i = -1, \forall i\} \implies p_i \succ U(0, 1)$
- a.k.a p-values have stochastically larger distribution than $U(0, 1)$
- a.k.a p-values are conservative, $P_{H_{0i}}(Y_i > y_i)$ "should be" smaller

---

### How does conservative look like?

```{r Conservative-P-Values}
y1 <- rnorm(n = 100, mean = 0)
p1 <- 1 - pnorm(y1, mean = 0)
y2 <- rnorm(n = 100, mean = -1)
p2 <- 1 - pnorm(y2, mean = 0)

```

```{r echo=FALSE}
df <- tibble(p_val = c(p1, p2),
             mu = factor(c(rep(0, 100), rep(-1, 100))))
h <- df %>%
  ggplot(aes(p_val, fill = mu)) +
  geom_histogram(bins = 10, alpha = 0.5)

cdf <- df %>%
  ggplot(aes(p_val, color = mu)) +
  stat_ecdf()
```

.pull-left[
```{r Conservative-Hists, echo=FALSE, out.width="100%"}
h +
  labs(y = NULL) +
  theme_light() +
  theme(axis.text = element_text(size = 20),
        axis.title.x = element_text(size = 20),
        legend.text = element_text(size = 20),
        legend.title = element_text(size = 20))
```
]

.pull-right[
```{r Conservative-CDFs, echo=FALSE, out.width="100%"}
cdf +
  labs(y = "F(p_val)") +
  theme_light() +
  theme(axis.text = element_text(size = 20),
        axis.title.y = element_text(size = 20),
        axis.title.x = element_text(size = 20),
        legend.text = element_text(size = 20),
        legend.title = element_text(size = 20))
```
]

---

class: section-slide

# Qualitative Interaction as a MTP

---

### Qualitative Interaction as MTP

- $n$ subgroups or independent studies
- $y_i \sim N(\mu_i, \sigma_i^2)$
- Single study "positive" null: $H^+_{0i} = \{\mu_i \ge 0\}$
- Global "positive" null: $H_0^+ = \cap_{i=1}^n H^+_{0i} = \{\mu_i \ge 0, \forall i\}$
- Global "negative" null: $H_0^- = \cap_{i=1}^n H^-_{0i} = \{\mu_i \le 0, \forall i\}$

 $\implies$ Null hypothesis of NO qualitative interaction:
 $$H_0 = H_0^+ \cup H_0^-$$
 
Reject $H_0$ if both $H_0^+$ and $H_0^-$ are rejected at level $\alpha$.

.insight[
`r emo::ji("bulb")` Why don't we need a multiple comparisons correction here?
]

---

### So we're good?

- Forget the t-test or ME model
- For $H_0^+$:
  - Get the p-value $p_i$ from each study for $H^+_{0i}$
  - Adjust $p_1, ..., p_n$ with your favorite MTP handler: Bonferroni, Fisher, BH, ...
  - Test the global null $H_0^+$ e.g. with Bonferroni if $p_+^{B} \le \alpha$
- Repeat for $H_0^-$, reject if both $H_0^+$ and $H_0^-$ are rejected
- Could also report a global p-value which is $\max(p_{+}^{B}, p_{-}^{B})$
- Done.

---

### Qualitative Interaction Scenario

In reality $\mu_1 = \mu_2 = 3$ and $\mu_3 = ... = \mu_{100} = -10$

```{r, echo=FALSE}
set.seed(1)
```

```{r}
y3 <- rnorm(100, mean = c(3, 3, rep(-10, 98)))
p3 <- 1 - pnorm(y3, mean = 0)

signif(head(p3), digits = 2)
```

```{r echo=FALSE}
df <- tibble(p_val = c(p1, p3),
             mu = factor(c(rep("exact", 100), rep("QI", 100)),
                         levels = c("QI", "exact")))
h <- df %>%
  ggplot(aes(p_val, fill = mu)) +
  geom_histogram(bins = 10, alpha = 0.5)

cdf <- df %>%
  ggplot(aes(p_val, color = mu)) +
  stat_ecdf()
```

.pull-left[
```{r Conservative-Hists2, echo=FALSE, out.width="75%"}
h +
  labs(y = NULL) +
  theme_light() +
  theme(axis.text = element_text(size = 20),
        axis.title.x = element_text(size = 20),
        legend.text = element_text(size = 20),
        legend.title = element_text(size = 20))
```
]

.pull-right[
```{r Conservative-CDFs2, echo=FALSE, out.width="75%"}
cdf +
  labs(y = "F(p_val)") +
  theme_light() +
  theme(axis.text = element_text(size = 20),
        axis.title.y = element_text(size = 20),
        axis.title.x = element_text(size = 20),
        legend.text = element_text(size = 20),
        legend.title = element_text(size = 20))
```
]

---

### Conservative p-values: particularly bad for QI

- $H^-_0$ will never be rejected (Bonferroni (and friends) lose power!)
- $H^+_0$ will always be rejected

```{r}
p_pos <- 1 - pnorm(y3, mean = 0)
p_neg <- pnorm(y3, mean = 0)

p_global_bonferroni(p_pos); p_global_bonferroni(p_neg)

max(p_global_bonferroni(p_pos), p_global_bonferroni(p_neg)) 
```

- So $H_0$ of no QI will never be rejected! Can't "prove" QI when it clearly is the case.

---

### To summarize

> Intuitively, if we do observe (p1, p2, p3 ... , p100) = (0.001, 0.001, 1, ..., 1), the first thing to be noticed is there are exceptionally many large p-values. This indicates many conservative tests. Naturally, we would like to "ignore" these large p-values and only use the two smaller ones, with which we can easily reject the global null. However, we cannot simply remove the large p-values because this would be data snooping and make the subsequent inference invalid.

<center><img src = "images/cooper_results.png" style="width: 23%"></center>

---

class: section-slide

# Conditional Test

---

### What are Zhao et al. suggesting?

- Given $p_1, ..., p_n$ independent p-values
- Set a fixed threshold parameter $0 < \tau \le 1$
- Let $S_\tau = \{i|p_i \le \tau\}$ (group of p-values smaller than $\tau$)
- From basic probability: if $p_i \sim U(0, 1)$ then $p_i|p_i \le \tau \sim U(0, \tau)$ then $p_i/\tau|\{i \in S_\tau\} \sim U(0, 1)$


- Now take these *conditional* p-values $p_i/\tau|\{i \in S_\tau\}$ and perform your favorite MTP procedure $p$:

$$p(p_1, ..., p_n; \tau) = p(p_i/\tau|\{i \in S_\tau\})$$

- Where: $p(\emptyset) = 1$

.insight[
`r emo::ji("bulb")` What happens when $\tau = 1$?
]

---

### Example: Conditional Bonferroni for a Global Null

- Reject a global null $H_0$ if $|S_\tau| > 0$ and:

$$\min_i{(p_i/\tau)} \le \alpha / |S_\tau|$$

- Or as we put it "Conditional Bonferroni" p-value would be:

$$p^{CB}(p_1, ... , p_n; \tau) = \min(|S_\tau| \cdot \min_i{(p_i/\tau)}, 1)$$

- In our earlier example for $\tau = 0.8$:

```{r}
p_global_bonferroni(p3[p3 <= 0.8] / 0.8)
```

---

### Conditional Testing of Qualitative Interaction

```{r}
p_pos <- 1 - pnorm(y3, mean = 0)
p_neg <- pnorm(y3, mean = 0)

p_global_bonferroni(p_pos[p_pos <= 0.8] / 0.8)
p_global_bonferroni(p_neg[p_neg <= 0.8] / 0.8)

max(p_global_bonferroni(p_pos[p_pos <= 0.8] / 0.8), p_global_bonferroni(p_neg[p_neg <= 0.8] / 0.8))
```

---

### Back to Educational Intervention

<center><img src = "images/cooper_conditional_test_for_qi.png" style="width: 100%"></center>