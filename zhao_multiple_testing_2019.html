<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Multiple Testing When Many p-Values are Uniformly Conservative</title>
    <meta charset="utf-8" />
    <meta name="author" content="Giora Simchoni" />
    <meta name="date" content="2020-10-30" />
    <head>
      <link rel="icon" href="../DSApps_logo.jpg" type="image/jpg"> 
      <link rel="shortcut icon" href="../DSApps_logo.jpg" type="image/jpg">
    </head>
    <link rel="stylesheet" href="slides.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">


class: title-slide

## Multiple Testing When Many P-Values are Uniformly Conservative

#### Qingyuan Zhao, Dylan S. Small, and Weijie Su (2019)

##### Presented by: Giora Simchoni

### Multiple Comparisons and Selective Inference Sem. A 2020

#### Stat. and OR Department, TAU
#### 2020-11-05

---



layout: true

&lt;div class="my-footer"&gt;
  &lt;span&gt;
    &lt;a href="https://www.tandfonline.com/doi/full/10.1080/01621459.2018.1497499" target="_blank"&gt;Multiple Testing When Many P-Values are Uniformly Conservative
    &lt;/a&gt;
  &lt;/span&gt;
&lt;/div&gt;

---



class: section-slide

# At Highest Level

---

## There's a Story

.no_shadow[
&lt;center&gt;&lt;img src = "images/high_level_story.png" style="width: 100%"&gt;&lt;/center&gt;
]

---

class: section-slide

# Motivation

---

### Educational Intervention

[Cooper et al. (2003)](https://www.jstor.org/stable/3516042) Meta-Analysis:

&lt;center&gt;&lt;img src = "images/cooper_abstract.png" style="width: 70%"&gt;&lt;/center&gt;

---

### A Typical (Simplified) Single-Study Model

`$$y_j = \beta_0 + \beta_MX_j + \epsilon_j$$`

Where:

`$$y_j = \text{Student j "achievement"}$$`

`$$X_j = \begin{cases}
      1, &amp; \text{Student j in Modified Calendar}\ \\
      0, &amp; \text{Otherwise}
    \end{cases}$$`

`$$\epsilon_j \sim N(0, \sigma^2)$$`

And we're interested in:

`$$H_0: \beta_M \leq 0 \space vs. \space H_1: \beta_M &gt; 0$$`

(Yes, in some studies this could literally be a t-test)

---

### A Typical (Simplified) Meta-Study Model

- Observe `\(n\)` studies for which we only have the bottom line, such as treatment effect `\(\beta_{M_i}\)` or its p-value `\(p_i\)`
- Each `\(\beta_{M_i}\)` comes with its own scale or `\(\sigma_i\)`
- Is there a "global" effect?
- One approach is to take the *effect size*s `\(d_i = \frac{\beta_{M_i}}{\sigma_i}\)`
- Let `\(\mu_d =E(d)\)`
- Use a single sample t/z-test to test the global null hypothesis:

`$$H_0: \mu_d \le 0 \space vs. \space H_1: \mu_d &gt; 0$$`

---

### A (Still Simplified) Meta-Study Mixed Model

`$$y_i = \mu + b_{S_i} + \epsilon_i$$`

Where:

`$$y_i = \text{Study i treatment effect or } \beta_{M_i}$$`
`$$b_{S_i} \sim N(0, \sigma_S^2) = \text{Study i random effect}$$`
`$$\epsilon_i \sim N(0, \sigma_i^2)$$`
Where `\(\sigma_i^2\)` is known from Study `\(i\)`.

Still the global null hypothesis would be:

`$$H_0: \mu \le 0 \space vs. \space H_1: \mu &gt; 0$$`

---

### Result: "quite small"

.pull-left[
&lt;img src = "images/cooper_results_stem_leaf.png" style="width: 100%"&gt;

]
.pull-right[
&lt;img src = "images/cooper_results.png" style="width: 90%"&gt;
]

---

### But could there be a (qualitative) interaction?

.pull-left[

#### Quantitative (Ordinal) Interaction

&lt;img src="images/Ordinal-Interaction-1.png" width="100%" /&gt;

]

.pull-right[

#### Qualitative (Disordinal) Interaction

&lt;img src="images/Disrdinal-Interaction-1.png" width="100%" /&gt;

]

---

#### Why is the ME model unsuitable for testing qualitative interaction?

- `\(\sigma^2_S &gt; 0\)` significantly, was found. What does that mean?
- So, go to a Fixed Effects model and make school/district a categorical variable with ~50 levels?...
- Can the ME model incorporate interaction? Can't guess apriori (and therefore put in the model) which groups (schools, districts) belong to positive/negative treatment effect

---

class: section-slide

# Meta-Analysis as a Multiple Testing Problem

---

### Meta-Analysis as MTP

- `\(n\)` subgroups or independent studies
- `\(y_i \sim N(\mu_i, \sigma_i^2)\)` [Study i treatment effect or `\(\beta_{M_i}\)`]
- Single study null hypothesis: `\(H_{0i} = \{\mu_i \le 0\}\)`
- Global null hypothesis: `\(H_0 = \cap_{i=1}^n H_{0i} = \{\mu_i \le 0, \forall i\}\)`

`\(\implies\)`

- Forget the t-test or ME model
- Get the p-value `\(p_i\)` from each study for `\(H_{0i}\)`
- Treat `\(p_1, ..., p_n\)` with your favorite MTP handler: Bonferroni, Fisher, BH, ...
- Test the global null `\(H_0\)` accordingly
- E.g. with Bonferroni reject `\(H_0\)` if `\(min(p_i) \le \alpha/n\)`

---

### Testing a Global Null

- Think of any global test that is associated with a series of p-values adjusting function `\(p: [0, 1]^n \rightarrow [0, 1]\)`

- Bonferroni is really: `\(p^B(p_1, ... , p_n) = \min(n \cdot \min_i{p_i}, 1)\)`


```r
p_global_bonferroni &lt;- function(p_vals) {
  n &lt;- length(p_vals)
  return(min(n * min(p_vals), 1))
}
```

- Looks good, right?

---

### The Problem of Conservative Tests

&lt;img src="images/Conservative-P-Value-Demo-1.png" width="100%" /&gt;

---

### The Problem of Conservative Tests

- Suppose `\(Y_1, ..., Y_{100}\)` are `\(N(\mu_i, 1)\)` RVs
- Global null: `\(H_0 = \cap_{i=1}^n H_{0i} = \{\mu_i \le 0, \forall i\}\)`
- Observe `\(y_1, ..., y_n\)`
- p-value would be: `\(p_i = P_{H_{0i}}(Y_i &gt; y_i) = 1 - \phi(y_i)\)`
- Calculate `\(p_1, ..., p_n\)`
- If in reality `\(\{\mu_i = 0, \forall i\} \implies p_i \sim U(0, 1)\)`
- If in reality e.g. `\(\{\mu_i = -1, \forall i\} \implies p_i \succ U(0, 1)\)`
- a.k.a p-values have stochastically larger distribution than `\(U(0, 1)\)`
- a.k.a p-values are conservative, `\(P_{H_{0i}}(Y_i &gt; y_i)\)` "should be" smaller

---

### How does conservative look like?


```r
y1 &lt;- rnorm(n = 100, mean = 0)
p1 &lt;- 1 - pnorm(y1, mean = 0)
y2 &lt;- rnorm(n = 100, mean = -1)
p2 &lt;- 1 - pnorm(y2, mean = 0)
```



.pull-left[
&lt;img src="images/Conservative-Hists-1.png" width="100%" /&gt;
]

.pull-right[
&lt;img src="images/Conservative-CDFs-1.png" width="100%" /&gt;
]

---

class: section-slide

# Qualitative Interaction as a MTP

---

### Qualitative Interaction as MTP

- `\(n\)` subgroups or independent studies
- `\(y_i \sim N(\mu_i, \sigma_i^2)\)`
- Single study "positive" null: `\(H^+_{0i} = \{\mu_i \ge 0\}\)`
- Global "positive" null: `\(H_0^+ = \cap_{i=1}^n H^+_{0i} = \{\mu_i \ge 0, \forall i\}\)`
- Global "negative" null: `\(H_0^- = \cap_{i=1}^n H^-_{0i} = \{\mu_i \le 0, \forall i\}\)`

 `\(\implies\)` Null hypothesis of NO qualitative interaction:
 `$$H_0 = H_0^+ \cup H_0^-$$`
 
Reject `\(H_0\)` if both `\(H_0^+\)` and `\(H_0^-\)` are rejected at level `\(\alpha\)`.

.insight[
ðŸ’¡ Why don't we need a multiple comparisons correction here?
]

---

### So we're good?

- Forget the t-test or ME model
- For `\(H_0^+\)`:
  - Get the p-value `\(p_i\)` from each study for `\(H^+_{0i}\)`
  - Adjust `\(p_1, ..., p_n\)` with your favorite MTP handler: Bonferroni, Fisher, BH, ...
  - Test the global null `\(H_0^+\)` e.g. with Bonferroni if `\(p_+^{B} \le \alpha\)`
- Repeat for `\(H_0^-\)`, reject if both `\(H_0^+\)` and `\(H_0^-\)` are rejected
- Could also report a global p-value which is `\(\max(p_{+}^{B}, p_{-}^{B})\)`
- Done.

---

### Qualitative Interaction Scenario

In reality `\(\mu_1 = \mu_2 = 3\)` and `\(\mu_3 = ... = \mu_{100} = -10\)`




```r
y3 &lt;- rnorm(100, mean = c(3, 3, rep(-10, 98)))
p3 &lt;- 1 - pnorm(y3, mean = 0)

signif(head(p3), digits = 2)
```

```
## [1] 0.00880 0.00073 1.00000 1.00000 1.00000 1.00000
```



.pull-left[
&lt;img src="images/Conservative-Hists2-1.png" width="75%" /&gt;
]

.pull-right[
&lt;img src="images/Conservative-CDFs2-1.png" width="75%" /&gt;
]

---

### Conservative p-values: particularly bad for QI

- `\(H^-_0\)` will never be rejected (Bonferroni (and friends) lose power!)
- `\(H^+_0\)` will always be rejected


```r
p_pos &lt;- 1 - pnorm(y3, mean = 0)
p_neg &lt;- pnorm(y3, mean = 0)

p_global_bonferroni(p_pos); p_global_bonferroni(p_neg)
```

```
## [1] 0.07271705
```

```
## [1] 1.297286e-32
```

```r
max(p_global_bonferroni(p_pos), p_global_bonferroni(p_neg)) 
```

```
## [1] 0.07271705
```

- So `\(H_0\)` of no QI will never be rejected! Can't "prove" QI when it clearly is the case.

---

### To summarize

&gt; Intuitively, if we do observe (p1, p2, p3 ... , p100) = (0.001, 0.001, 1, ..., 1), the first thing to be noticed is there are exceptionally many large p-values. This indicates many conservative tests. Naturally, we would like to "ignore" these large p-values and only use the two smaller ones, with which we can easily reject the global null. However, we cannot simply remove the large p-values because this would be data snooping and make the subsequent inference invalid.

&lt;center&gt;&lt;img src = "images/cooper_results.png" style="width: 23%"&gt;&lt;/center&gt;

---

class: section-slide

# Conditional Test

---

### What are Zhao et al. suggesting?

- Given `\(p_1, ..., p_n\)` independent p-values
- Set a fixed threshold parameter `\(0 &lt; \tau \le 1\)`
- Let `\(S_\tau = \{i|p_i \le \tau\}\)` (group of p-values smaller than `\(\tau\)`)
- From basic probability: if `\(p_i\)` are exact and `\(p_i \sim U(0, 1)\)` then `\(p_i|p_i \le \tau \sim U(0, \tau)\)` then `\(p_i/\tau|\{i \in S_\tau\} \sim U(0, 1)\)`


- Now take these *conditional* p-values `\(p_i/\tau|\{i \in S_\tau\}\)` and perform your favorite MTP procedure `\(p\)`:

`$$p(p_1, ..., p_n; \tau) = p(p_i/\tau|\{i \in S_\tau\})$$`

- Where: `\(p(\emptyset) = 1\)`

.insight[
ðŸ’¡ What happens when `\(\tau = 1\)`?
]

---

### Example: Conditional Bonferroni for a Global Null

- Reject a global null `\(H_0\)` if `\(|S_\tau| &gt; 0\)` and:

`$$\min_i{(p_i/\tau)} \le \alpha / |S_\tau|$$`

- Or as we put it "Conditional Bonferroni" p-value would be:

`$$p^{CB}(p_1, ... , p_n; \tau) = \min(|S_\tau| \cdot \min_i{(p_i/\tau)}, 1)$$`

- In our earlier example for `\(\tau = 0.8\)`:


```r
p_global_bonferroni(p3[p3 &lt;= 0.8] / 0.8)
```

```
## [1] 0.001817926
```

---

### Conditional Testing of Qualitative Interaction


```r
tau &lt;- 0.8
p_pos &lt;- 1 - pnorm(y3, mean = 0)
p_neg &lt;- pnorm(y3, mean = 0)

(p_pos_gl &lt;- p_global_bonferroni(p_pos[p_pos &lt;= tau] / tau))
```

```
## [1] 0.001817926
```

```r
(p_neg_gl &lt;- p_global_bonferroni(p_neg[p_neg &lt;= tau] / tau))
```

```
## [1] 1.589175e-32
```

```r
max(p_pos_gl, p_neg_gl)
```

```
## [1] 0.001817926
```

---

### Back to Educational Intervention

&lt;center&gt;&lt;img src = "images/cooper_conditional_test_for_qi.png" style="width: 100%"&gt;&lt;/center&gt;

---

class: section-slide

# Conditional Test: Assumptions

---

### Defintion 1: Validity

A global test is *valid* if `\(P(p(p_1, ..., p_n) \le \alpha) \le \alpha\)`
for all `\(0 \le \alpha \le 1\)` under the global null `\(H_0\)`

Is Conditional Bonferroni global p-value valid?

$$
`\begin{aligned}
&amp;P(p^{CB}(p_1, ..., p_n) \le \alpha) = P(|S_\tau| \cdot \min{(p_i/\tau)} \le \alpha) \\
&amp;= P(\bigcup \{p_i/\tau \le \alpha/|S_\tau|\}) \\
&amp;\le \sum P(p_i/\tau \le \alpha/|S_\tau|) \\
&amp;\le \sum_1^{|S_\tau|} \alpha/|S_\tau| = \alpha
\end{aligned}`
$$
But this only holds if all `\(p_i/\tau\)` are valid!

What if `\(P(p_i/\tau \le \alpha/|S_\tau|) &lt; \alpha/|S_\tau|\)`?

---

### Definition 2: Uniform Validity and Conservativity

A global test is *uniformly valid* if for all `\(0 &lt; \tau &lt; 1\)` such that `\(P(p_i \le \tau) &gt; 0\)`, `\(p_i/\tau\)` given `\(p_i \le \tau\)` is valid.

A p-value is called *uniformly conservative* if it is conservative and uniformly valid.

So, by definition:

**Proposition 2:** The conditional test using any fixed `\(0 &lt; \tau \le 1\)` and any valid global test is also valid if `\(p_1, p_2, ..., p_n\)` are independent
and uniformly valid.

One conclusion is you can use the conditional test when your p-value test is unfirmly valid/conservative.

---

### Which Tests are Uniformly Valid/Conservative?

Any valid test `\(p_i\)` with CDF `\(F_i(x) = P(p_i \le x)\)` for which:

$$
F_i(\tau x) \le xF_i(\tau), \forall 0 \le x, \tau \le 1 
$$
Because:

`\(F_i(\tau x) = P(p_i \le \tau x) = P(p_i/\tau \le x)\)`

`\(F_i(\tau) \le 1\)`

So:

`\(P(p_i/\tau \le x) \le x\)` which means `\(p_i\)` is uniformly valid.

And whether it is uniformly conservative depends on `\(p_i/\tau\)` being conservative or not.

---

### Which means...

- Geometrically, this means that the function `\(F_i(x)\)` is always below the segment from `\((0, 0 = F_i(0))\)` to `\((\tau, F_i(\tau))\)` if `\(0 \le x \le \tau\)`.

&lt;center&gt;&lt;img src = "images/uniformly_conservative.png" style="width: 100%"&gt;&lt;/center&gt;

---

### Which means...

- A sufficient condition (but not necessary) for uniform conservativeness is convexity of the CDF

- From Calculus: When the CDF `\(F(x)\)` is differentiable, convexity of `\(F(x)\)` is equivalent to the density `\(f(x)\)` being monotonically increasing

- Where would we get a statistic `\(T(Y)\)` with monotonically increasing `\(f\)`?

- From Statistical Theory: The one dimensional exponential family with parameter `\(\theta\)` has monotone likelihood ratio (MLR) in statistic `\(T(Y)\)`, meaning for every `\(\theta_2 &gt; \theta_1\)` the likelihood ratio `\(f_{\theta_2}(y) / f_{\theta_1}(y)\)` is a non-decreasing function of `\(T(Y)\)`, and the uniformly most powerful test at level `\(\alpha\)` would be to reject `\(H_0: \theta \le \theta_0\)` if `\(T(Y) \ge C\)` and `\(P_{\theta_0}(T(Y) \ge C) = \alpha\)`

---

### Which means...

- **Proposition 3:** When the true `\(\theta &lt; \theta_0\)`, the UMP one-sided test of `\(H_0: \theta \le \theta_0\)` vs. `\(H_1: \theta &gt; \theta_0\)` in the one-dimensional exponential family is uniformly conservative

- So for example for `\(Y_i \sim N(\mu_i, \sigma_i^2)\)` **where `\(\sigma_i\)` is known** and we're interested in the one sided test `\(H^-_{0i}: \mu_i \le 0\)`. If the true `\(\mu_i &lt; 0\)` the UMP one-sided test using `\(Y_i\)` is uniformly conservative and we can go ahead and use the conditional test!

---

class: section-slide

# Conditional Test: Power Simulations

---

### Will the global one-sided null be rejected?

"1 strong 99 very conservative"


```r
n_sim &lt;- 10000
reject &lt;- numeric(n_sim); reject_cond &lt;- numeric(n_sim)

for (j in 1:n_sim) {
  y &lt;- rnorm(100, mean = c(4, rep(-4, 99)))
  p &lt;- 1 - pnorm(y, mean = 0)
  reject[j] &lt;- as.integer(p_global_bonferroni(p) &lt; 0.05)
  reject_cond[j] &lt;- as.integer(p_global_bonferroni(p[p &lt;= 0.8]/0.8) &lt; 0.05)
}
mean(reject); mean(reject_cond)
```

```
## [1] 0.758
```

```
## [1] 0.9856
```

---

### Will the global one-sided null be rejected?

&lt;center&gt;&lt;img src = "images/simulations1.png" style="width: 100%"&gt;&lt;/center&gt;

---

### Will the QI null be rejected?

"50 positive 50 negative"


```r
reject &lt;- numeric(n_sim); reject_cond &lt;- numeric(n_sim)

for (j in 1:n_sim) {
  y &lt;- rnorm(100, mean = c(rep(1, 50), rep(-1, 50)))
  p_pos &lt;- 1 - pnorm(y, mean = 0)
  p_neg &lt;- pnorm(y, mean = 0)
  p_pos_gl &lt;- p_global_bonferroni(p_pos)
  p_neg_gl &lt;- p_global_bonferroni(p_neg)
  p &lt;- max(p_pos_gl, p_neg_gl)
  reject[j] &lt;- as.integer(p &lt; 0.05)
  p_pos_gl &lt;- p_global_bonferroni(p_pos[p_pos &lt;= 0.8] / 0.8)
  p_neg_gl &lt;- p_global_bonferroni(p_neg[p_neg &lt;= 0.8] / 0.8)
  p &lt;- max(p_pos_gl, p_neg_gl)
  reject_cond[j] &lt;- as.integer(p &lt; 0.05)
}
mean(reject); mean(reject_cond)
```

```
## [1] 0.1817
```

```
## [1] 0.2111
```

---

### Will the QI null be rejected?

&lt;center&gt;&lt;img src = "images/simulations2.png" style="width: 100%"&gt;&lt;/center&gt;

---

class: section-slide

# Conditional Test: Adaptive Threshold

---

### How to choose Ï„ without sacrificing the validity of the test?

- **Proposition 4:** Let `\(F_x = \sigma(\{p_i| p_i \ge x\})\)` be the backward filtration for `\(0 \le x \le 1\)`. If `\(\tau = \tau(p_1, ..., p_n)\)` is a backward stopping time in the sense that `\(\{\tau \ge x\}\)` is `\(F_x\)`-measurable for any
`\(0 \le x \le 1\)`, then Proposition 2 still holds.

- Which basically means (see proof) you're good if you (say, interactively):

  - decide on a decreasing sequence `\(\tau_1 &gt; ... &gt; \tau_K\)`
  - at stage `\(k\)` base your criterion of stopping **ONLY** on `\(\{p_i|p_i &gt; \tau_k \}\)` [the p-values you've discarded so far]
  - apply global test on `\(\{p_i/\tau|p_i \le \tau\}\)` if `\(\tau\)` is the `\(\tau_k\)` you've stopped at

---

### What would be a good stopping criterion?

- Look again at "Conditional Bonferroni":

$$
`\begin{aligned}
&amp;p^{CB}(p_1, ... , p_n; \tau) = \min(|S_\tau| \cdot \min_i{(p_i/\tau)}, 1) \\
&amp;= \min(\frac{|S_\tau|}{\tau} \cdot \min_i{(p_i)}, 1)
\end{aligned}`
$$

- We'd want to minimize `\(\frac{|S_\tau|}{\tau}\)`!

- Intuitively we'd want to discard as many `\(p_i\)` (i.e. decrease `\(|S_\tau|\)`) in the minimum amount of steps (i.e. increase `\(\tau\)`)

- But how will we know we've reached the minimum `\(\frac{|S_\tau|}{\tau}\)` "in real time"?

---


```r
p_values &lt;- c(1.0, 1.0, 0.95, 0.9, 0.8, 0.7, 0.5, 0.2, 0.1, 0.01, 0.01, 0.001)
taus &lt;- seq(0.95, 0.05, -0.05)
K &lt;- length(taus)
S_t_card &lt;- numeric(K)
for (k in 1:K) {
  S_t_card[k] &lt;- length(p_values[p_values &lt;= taus[k]])
}

plot(1:K, S_t_card / taus, xlab = "k")
```

&lt;img src="images/Minimizing-S-Card-1.png" width="100%" /&gt;

---

- Let `\(F\)` be the (average) CDF of the p-values: `\(F(x) = (1/n)\sum F_i(x)\)`
- 
---

class: section-slide

# Other Stuff

---

- Testing for Practical Importance
- When the p-values are dependent
- Power of Conditional Bonferroni over Bonferroni
- Beyond global testing
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
